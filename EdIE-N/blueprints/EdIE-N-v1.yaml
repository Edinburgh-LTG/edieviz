# Name of experiment and blueprint
name: EdIE-N-v1
seed: 13
device: &device cuda:0
# Results are slightly different if you use cpu
# device: &device cpu

# Paths specific to experiments
paths:
  $module: edien
  $classname: EdIENPath

# Data
data:
  name: ESS
  $module: edien.data
  $classname: DatasetEncoder
  dataset:
    $module: edien.data
    $classname: EdIEDataset
    train_paths:
    - radiology/ess/train
    dev_path: radiology/ess/dev
    test_path: radiology/ess/test
  inputs:
    - &chars chars
    - &words tokens
  targets:
    - &ner ner_tags
    - &mod mod_tags
    - &neg negation
  metrics:
    &loss loss:
      $module: edien.metrics
      $classname: Average
      label: *loss
    *ner:
      $module: edien.metrics
      $classname: BIOF1
      label: *ner
    *mod:
      $module: edien.metrics
      $classname: BIOF1
      label: *mod
    *neg:
      $module: edien.metrics
      $classname: Accuracy
      label: *neg
  vocab_encoder:
    $module: edien.data
    $classname: VocabEncoder
    load_if_exists: false
    vocabs:
      *ner:
        $module: edien.vocab
        $classname: Vocab
        handle_unk: false
        filename: ner_tags.vocab
        size: &ner_embeds 24
        axis: 1
      *mod:
        $module: edien.vocab
        $classname: Vocab
        handle_unk: false
        filename: mod_tags.vocab
        size: &mod_embeds 9
        axis: 1
      *chars:
        $module: edien.vocab
        $classname: Vocab
        handle_unk: true
        size: &char_embeds 100
        filename: chars.vocab
        threshold: 12
        axis: 2
      *neg:
        $module: edien.vocab
        $classname: Vocab
        handle_unk: false
        filename: negation.vocab
        size: &neg_embeds 2
        axis: 1
      *words:
        $module: edien.vocab
        $classname: Vocab
        handle_unk: true
        size: &word_embeds 1668
        filename: words.vocab
        threshold: 5
        axis: 1
  formatter:
    $module: edien.data
    $classname: Sentences

model:
  $module: edien.models
  $classname: EdFactorN
  optimizer:
    $module: edien.optim
    $classname: TorchOptWrapper
    classname: SGD
    lr: 1.0
  scheduler:
    $module: edien.optim
    $classname: TorchScheduleWrapper
    lib: pytorch_transformers.optimization
    classname: WarmupConstantSchedule
    warmup_steps: 200
  batch_size: 16
  checkpoint_every: 200
  patience: 10
  max_epochs: 1000
  patience_renewer: ner_tags_f1
  model:
    $module: edien.models
    $classname: EdFFMT
    encoder:
      $module: edien.components
      $classname: BiLSTMSentenceEncoder
      encoder:
        $module: edien.components
        $classname: Embedder
        inputs:
          chars:
            $module: edien.components
            $classname: CNNWordEncoder
            in_size: 100
            embed_dim: 15
            project_dim: 128
            char_dropout: 0.1
            cnn_dropout: null
            project_dropout: null
            batch_norm: true
            positional_embed: false
            device: *device
          tokens:
            $module: edien.components
            $classname: PaddedEmbedding
            in_size: *word_embeds 
            embed_dim: 128
            dropout: 0.5
        composition: concat
        dropout: null
      num_layers: 1
      hidden_dim: 256
      # Below only has effect if more than one LSTM layer
      # due to CUDA implementation / pytorch interface
      dropout: null
    num_samples: 0
    device: *device 
    tasks:
      mod_tags:
        $module: edien.components
        $classname: TaskMLP
        in_dim: 512
        hidden_dim: 512
        num_labels: *mod_embeds
        dropout: 0.25
        batch_norm: false
        use_crf: true
      ner_tags:
        $module: edien.components
        $classname: TaskMLP
        in_dim: 512
        hidden_dim: 512
        num_labels: *ner_embeds
        dropout: 0.25
        batch_norm: false
        use_crf: true
      negation:
        $module: edien.components
        $classname: TaskMLP
        in_dim: 512
        hidden_dim: 512
        num_labels: 1
        pipe_inputs:
          - *ner
          - *mod
        dropout: 0.25
        batch_norm: false
        use_crf: false
